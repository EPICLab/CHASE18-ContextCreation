%!TEX root = main.tex

\section{Methodology}

\boldification{We observed 5 participants at work. Out of these we chose 3 participants who represent diverse styles of programming. P1 followed Test driven development approach, P4 was a conscientious programmer and S was a tinkerer.}
We conducted a lab study in which we observed six student participants while programming. Participants P1 through P5 were given a prompt which required planning, design, and development of software that mimics the rules that govern a traffic intersection. P6 was observed programming on a real-world problem while developing an IDE so that we could extend and confirm our observations beyond the domain of ``toy systems''. Within this paper, we focus on the results from P1, P4, and P6. This set of participants was chosen to represent a diverse set of programming styles; P1 adhered to the Test-Driven Development (TDD) model, P4 followed the Design-Driven Development (DDD) model, and P6 displayed a strong affinity for tinkering~\cite{Beckwith:2006}. By focusing on these three participants we are able to better understand their context while programming. 

\boldification{P1 and P4 was given to design(or redesign?? Clarify from Nick) a traffic simulator application that would be used for educational purposes. This style of programming is similar to maintenance or debugging. P6 was working on developing an IDE, which was more exploratory in nature with just some idea about the work and lesser constraints.}

P6 was not given a prompt because we wanted examine whether our initial observations from P1 to P5 would hold in a unconstrained real-world environment. This allowed us to differentiate observations that arose due to the specifics of the given traffic prompt, and those observations that appear to be universal across programming sessions and goals. The traffic prompt given to P1 to P5 is similar to a prompt use in previous software design studies~\cite{Mangano:2012}, and asks participants to design and implement a simulator for traffic intersections that can accommodate users experimenting with different timing and traffic light signal patterns. This prompt was designed to be easily understandable but difficult to implement, in order to challenge participants and be able to observe their use of context in problem solving.

\boldification{We captured their screen for an hour. P1 was asked to think aloud. We used his verbalizations to validate our understanding of context creation, usage and deletion}
Study sessions were time-boxed for a maximum of one hour, and organized as observational lab studies~\cite{Easterbrook:2008}. Participants were allowed to use their preferred development tools during the study, and video capture of their screen was recorded. Paper and pen were provided to participants for design, sketch, and note-taking purposes, and was collected at the conclusion of the study. Only P1 used a think-aloud, which was used to gain a better understanding of their mental model of context while problem solving.

\boldification{We unitized the videos using atlas.ti based on groups of coherent activities. For each unit, we noted the programming activities the participants performed and the artifacts they accesses and in what order. The set of programming activities were large adapted from [Yi wang?s] paper.}
To analyze the study session data, we unitized the screen capture data based upon both programming activity and artifact. We defined artifacts as web-pages, program elements open and visible on screen, and external notes. Example artifacts include intersection.scala as a file open in IntelliJ IDEA, and stackoverflow.com visited in Chrome Browser. Our codeset is based upon the codes developed by Yi Wang~\cite{Wang:2017}, which include: \texttt{navigation, reading questions, searching, reading search results, processing search results, viewing web resources, coding, run, debugging,} and \texttt{idle}. We do not use the \texttt{accidents} code since determining whether fast switching between artifacts is intentional, and therefore productive, is difficult to appraise from screen capture data. We added \texttt{communication} and \texttt{documentation} to the codeset, due to the nature of the tasks found in the traffic prompt and the think-aloud included in P1.

\boldification{Three of the authors coded the videos, following the IRR process. They obtained a jaccard index of 97.3\%. They also manually noted the order in which participants accessed the artifacts}

Using this codeset, the first , third and fourth authors coded a random set of data from P1 and P6 which represented <20\% of the total study data. After reaching >80\% inter-rater reliability (97.3\% Jaccard Index) across all three authors, the remaining data was coded individually by the same three authors.
